{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecursiveJsonSplitter\n",
    "\n",
    "- Author: [HeeWung Song(Dan)](https://github.com/heewungsong)\n",
    "- Design: \n",
    "- Peer Review:\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This JSON splitter generates smaller JSON chunks by performing a depth-first traversal of JSON data.\n",
    "\n",
    "While this splitter attempts to maintain nested JSON objects as much as possible, it will split objects when necessary to keep chunk sizes between min_chunk_size and max_chunk_size. When a value is a very large string rather than nested JSON, that string will not be split.\n",
    "\n",
    "If strict chunk size limits are required, you may consider using a Recursive Text Splitter to process these chunks after using this splitter.\n",
    "\n",
    "**Splitting Criteria**\n",
    "\n",
    "1. Text Splitting Method: Based on JSON values\n",
    "2. Chunk Size Measurement: Based on character count\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Basic JSON Splitting](#basic-json-splitting)\n",
    "- [Handling JSON Structure](#handling-json-structure)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- [Langchain RecursiveJsonSplitter](https://python.langchain.com/api_reference/text_splitters/json/langchain_text_splitters.json.RecursiveJsonSplitter.html#langchain_text_splitters.json.RecursiveJsonSplitter)\n",
    "- [Langchain How-to-split-JSONdata](https://python.langchain.com/docs/how_to/recursive_json_splitter/)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_openai\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"RecursiveJsonSplitter\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic JSON Splitting\n",
    "\n",
    "Let's explore the basic methods of splitting JSON data using `RecursiveJsonSplitter`.\n",
    "\n",
    "- JSON data preparation\n",
    "- `RecursiveJsonSplitter` configuration\n",
    "- Three splitting methods (split_json, create_documents, split_text)\n",
    "- Chunk size verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Load the JSON data.\n",
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of splitting JSON data using `RecursiveJsonSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "# Create a RecursiveJsonSplitter object that splits JSON data into chunks with a maximum size of 300\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `splitter.split_json()` function to recursively split JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively split JSON data. Use this when you need to access or manipulate small JSON fragments.\n",
    "json_chunks = splitter.split_json(json_data=json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `splitter.create_documents()` method to convert JSON data into document format.\n",
    "- Use `splitter.split_text()` method to split JSON data into a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}\n",
      "============================================================\n",
      "{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}\n"
     ]
    }
   ],
   "source": [
    "# Create documents based on JSON data.\n",
    "docs = splitter.create_documents(texts=[json_data])\n",
    "\n",
    "# Create string chunks based on JSON data.\n",
    "texts = splitter.split_text(json_data=json_data)\n",
    "\n",
    "# Print the first string.\n",
    "print(docs[0].page_content)\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# Print the split string chunks.\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling JSON Structure\n",
    "\n",
    "Let's explore how `RecursiveJsonSplitter` handles different JSON structures and their limitations.\n",
    "\n",
    "- List object size verification\n",
    "- JSON structure parsing\n",
    "- Using convert_lists parameter for list transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By examining `texts[2]`, which is one of the larger chunks, we can confirm that it contains a list object.\n",
    "\n",
    "- The reason why the second chunk exceeds the size limit (300) is because it contains a list object.\n",
    "- This is due to the fact that `RecursiveJsonSplitter` does not split list objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 197, 469, 210, 213, 237, 271, 191, 232, 215]\n",
      "{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}\n"
     ]
    }
   ],
   "source": [
    "# Let's check the size of the chunks\n",
    "print([len(text) for text in texts][:10])\n",
    "\n",
    "# When examining one of the larger chunks, we can see that it contains a list object\n",
    "print(texts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can parse the chunk at index 2 using the json module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id',\n",
       "     'in': 'path',\n",
       "     'required': True,\n",
       "     'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "    {'name': 'include_stats',\n",
       "     'in': 'query',\n",
       "     'required': False,\n",
       "     'schema': {'type': 'boolean',\n",
       "      'default': False,\n",
       "      'title': 'Include Stats'}},\n",
       "    {'name': 'accept',\n",
       "     'in': 'header',\n",
       "     'required': False,\n",
       "     'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Accept'}}]}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = json.loads(texts[2])\n",
    "json_data[\"paths\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert lists in JSON to `key:value` pairs in the form of `index:item` by setting the `convert_lists` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following preprocesses JSON and converts lists into dictionaries with index:item as key:value pairs\n",
    "texts = splitter.split_text(json_data=json_data, convert_lists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": {\"2\": {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": {\"0\": {\"type\": \"string\"}, \"1\": {\"type\": \"null\"}}, \"title\": \"Accept\"}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "# The list has been converted to a dictionary, and we'll check the result.\n",
    "print(texts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the document at a specific index in the `docs` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}'\n"
     ]
    }
   ],
   "source": [
    "# Check the document at index 2.\n",
    "print(docs[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
